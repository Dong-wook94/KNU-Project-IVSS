{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRGAN model\n",
    "<img src=\"model.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PReLU(_x):\n",
    "    alpha = tf.get_variable(\"alpha\", _x.get_shape()[-1], \n",
    "                            initializer = tf.constant_initializer(0.0), dtype = tf.int32)\n",
    "    return tf.nn.relu(_x) + alpha * (_x - tf.abs(_x)) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pixel shuffle\n",
    "\n",
    "\\\\(S_s  : [0,1]\\\\)<sup>(sH * sW * C)</sup> -> \\\\([0,1]\\\\)<sup>(H * W * s<sup>2</sup>c)</sup>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\\\\(S_s(I)\\\\)<sub>i,j,k</sub> = \\\\(I\\\\)<sub>si+k%s, sj+(k%s), k/s<sup>2</sup></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phaseShift(inputs, scale, shape_1, shape_2):\n",
    "    X = tf.reshape(inputs, shape_1)\n",
    "    X = tf.transpose(X, [0, 1, 3, 2, 4])\n",
    "    return tf.reshape(X, shape_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelShuffler(inputs, scale = 2):\n",
    "    size = tf.shape(inputs)\n",
    "    batch_size = size[0]\n",
    "    h = size[1]\n",
    "    w = size[2]\n",
    "    c = inputs.get_shape().as_list()[-1]\n",
    "    \n",
    "    # Get the target channel size\n",
    "    channel_target = c // (scale**2)\n",
    "    channel_factor = c // channel_target\n",
    "    \n",
    "    shape_1 = [batch_size, h, w, channel_factor // scale, channel_factor // scale]\n",
    "    shape_2 = [batch_size, h * scale, w * scale, 1]\n",
    "    \n",
    "    # Reshape and transpose for periodic shuffling for each channel\n",
    "    \n",
    "    input_split = tf.split(inputs, channel_target, axis = 3)\n",
    "    output = tf.concat([phaseShift(x, scale, shape_1, shape_2) for x in input_split], axis = 3)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_residual_block(inputs, output_dim, k_size, is_training, scope = 'G_b_res_block'):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        w1 = tf.get_variable('w1', [k_size, k_size, I.get_shape()[-1], output_dim],\n",
    "                            initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "        conv1 = tf.nn.conv2d(inputs, w1, strides = [1,1,1,1], padding = 'same')\n",
    "        b1 = tf.get_variable('b1', [output_dim], initializer = tf.constant_initializer(0.0))\n",
    "        conv1 = tf.nn.bias_add(conv1, b1)\n",
    "        \n",
    "        bn = tf.contrib.layers.batch_norm(conv1, is_training = is_training, scope = 'bn', \n",
    "                                           decay = 0.9, zero_debias_moving_mean = True)\n",
    "        prelu = PReLU(bn1)\n",
    "        \n",
    "        w2 = tf.get_variable('w2', [k_size, k_size, output_dim, output_dim],\n",
    "                            initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "        conv2 = tf.nn.conv2d(prelu, w2, strides = [1,1,1,1], padding = 'same')\n",
    "        b2 = tf.get_variable('b2', [output_dim], initializer = tf.constant_initializer(0.0))\n",
    "        conv2 = tf.nn.bias_add(conv2, b2)\n",
    "        \n",
    "        return conv2 + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_block(inputs, output_dim, k_size, scope = 'G_last_block'):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        w = tf.get_variable('w', [k_size, k_size, inputs.get_shape()[-1], output_dim],\n",
    "                           initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "        conv = tf.nn.conv2d(inputs, w, strides = [1,1,1,1], padding = 'same')\n",
    "        b = tf.get_variable('b', [output_dim], initializer = tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.bias_add(conv, b)\n",
    "        px = pixelShuffler(conv)\n",
    "        return PReLU(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_block(inputs, output_dims, k_size, s, is_training, scope = 'D_disc_block'):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        w = tf.get_variable('w', [k_size, k_size, inputs.get_shape()[-1], output_dim],\n",
    "                           initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "        conv = tf.nn.conv2d(inputs, w, strides = [s,s,s,s], padding = 'same')\n",
    "        b = tf.get_variable('b', [output_dim], initializer = tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.bias_add(conv, b)\n",
    "        return tf.nn.leaky_relu(conv, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-20700852caa9>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-20700852caa9>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    shape = [None, self.img_size[0]. self.img_size[1], self.channel])\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class SRGAN:\n",
    "    def __init__(self, sess, checkpoint_dir, log_dir, img_dir, img_size, channel, \n",
    "                 feature_root = 64, batch_size = 1, dropout = 0.5):\n",
    "        self.sess = sess\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "        self.channel = channel\n",
    "        self.feature_root = 64\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # saver 저장\n",
    "        \n",
    "    def generator(self, images):\n",
    "        \n",
    "        # conv -> PReLU\n",
    "        with tf.variable_scope('G_start') as scope:\n",
    "            w = tf.get_variable('w', [9, 9, self.channel, self.feature_root],\n",
    "                               initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "            conv = tf.nn.conv2d(images, w, strides = [1,1,1,1], padding = 'same')\n",
    "            b = tf.get_variable('b', [self.feature_root], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, a)\n",
    "            prelu = PReLU(conv)\n",
    "        \n",
    "        skip_late = prelu\n",
    "        skip = prelu\n",
    "        \n",
    "        # 5 B residual blocks\n",
    "        for i in range(5):\n",
    "            skip = B_residual_block(skip, self.feature_root, 3, is_training = True, \n",
    "                                    scope = 'G_b_res_block' + str(i))\n",
    "            \n",
    "        with tf.variable_scope('G_middle') as scope:\n",
    "            w = tf.get_variable('w', [3, 3, self.feature_root, self.feature_root],\n",
    "                               initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "            conv = tf.nn.conv2d(skip, w, strides = [1,1,1,1], padding = 'same')\n",
    "            b = tf.get_variable('b', [self.feature_root], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, a)\n",
    "            bn = tf.contrib.layers.batch_norm(conv, is_training = is_training, scope = 'bn', \n",
    "                                           decay = 0.9, zero_debias_moving_mean = True)\n",
    "            es = bn + skip_late\n",
    "        \n",
    "        last = last_block(es, self.feature_root*4, scope = 'G_last_block_0')\n",
    "        last = last_block(last, self.feature_root*4, scope = 'G_last_block_1')\n",
    "        with tf.variable_scope('G_last') as scope:\n",
    "            w = tf.get_variable('w', [3, 3, self.feature_root, self.feature_root],\n",
    "                               initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "            conv = tf.nn.conv2d(last, w, strides = [1,1,1,1], padding = 'same')\n",
    "            b = tf.get_variable('b', [self.feature_root], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, a)\n",
    "        \n",
    "        return conv\n",
    "    \n",
    "    def discriminator(self, images):\n",
    "        # Conv -> LeakyReLU\n",
    "        with tf.variable_scope('D_start') as scope:\n",
    "             w = tf.get_variable('w', [3, 3, self.feature_root, self.feature_root],\n",
    "                               initializer = tf.truncated_normal_initializer(stddev = 0.2))\n",
    "            conv = tf.nn.conv2d(last, w, strides = [1,1,1,1], padding = 'same')\n",
    "            b = tf.get_variable('b', [self.feature_root], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "            conv = tf.nn.bias_add(conv, a)\n",
    "            output = tf.nn.leaky_relu(conv, alpha = 0.2)\n",
    "        \n",
    "        features = self.feature_root\n",
    "        for i in range(7):\n",
    "            output = disc_block(output, features, (i+1)%2+1, scope = 'D_disc_block' + str(i))\n",
    "            if(i%2 == 0):\n",
    "                features = features * 2\n",
    "                \n",
    "        with tf.variable_scope('D_dense') as scope: \n",
    "            flat = tf.contrib.layers.flatten(output)\n",
    "            dense = tf.layers.dense(flat, 1024, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            dense = tf.nn.lrelu(dense)\n",
    "            dense = tf.layers.dense(dense, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            dense = tf.nn.sigmoid(dense)\n",
    "            \n",
    "        return dense\n",
    "\n",
    "    def build_model(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
